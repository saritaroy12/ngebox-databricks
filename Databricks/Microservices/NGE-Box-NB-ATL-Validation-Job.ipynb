{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7f28f45-67d3-44c9-b895-a8461d9b4995",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "## Import libraries\n",
    "import pyspark as ps\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from datetime import *\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "081884aa-83c4-42a3-a309-2c8c098f8d33",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve the parameter values\n",
    "job_id = dbutils.widgets.get(\"job_id\")\n",
    "usecase_id = dbutils.widgets.get(\"usecase_id\")\n",
    "\n",
    "# Print the parameter values\n",
    "print(f\"job_id: {job_id}\")\n",
    "print(f\"usecase_id: {usecase_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40df25d5-7869-425d-ad61-f9d6d2d78385",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class Validate_ATL:\n",
    "  def __init__(self):\n",
    "    self.query = \"Query About to fill\"\n",
    "    self.sql_df = pd.DataFrame()\n",
    "    self.data_json = {\"Data\":[]}    \n",
    "    self.usecase_id = None\n",
    "  \n",
    "  def logger(self, message):\n",
    "    print(message)\n",
    "    \n",
    "  def set_query_string(self, usecase_parm):\n",
    "        query = f\"\"\"with m(usecase_id, hist_retention) AS (SELECT mu.USECASE_ID,mu.hist_retention from com_us_alyt_ngebox.metadata_usecase mu where mu.USECASE_ID = '{usecase_parm}'),\n",
    "\n",
    "s(usecase_id,SUGGEST_EXTERNAL_ID_VOD__C,NGEBox_Record_ID) AS (select p.usecase_id, p.SUGGEST_EXTERNAL_ID_VOD__C, p.NGEBox_Record_ID from (select * from com_us_alyt_ngebox.ngebox_suggestion_requests_processed where usecase_id = '{usecase_parm}') p \n",
    "left join com_us_lake.rep_suggestion_vod__c s \n",
    "on p.SUGGEST_EXTERNAL_ID_VOD__C = s.SUGGESTION_EXTERNAL_ID_VOD__C  \n",
    "where (s.SUGGESTION_EXTERNAL_ID_VOD__C is NULL) \n",
    "or (s.SUGGESTION_EXTERNAL_ID_VOD__C is not null and s.DISMISSED_VOD__C = 0)),\n",
    "\n",
    "t(usecase_id,Record_ID,account_ID,Territory_name) as (select distinct tb1.usecase_id, tb1.NGEBOX_RECORD_ID, tb1.account_vod__c,tb4.geo_cd from (select * from com_us_alyt_ngebox.NGEBox_Suggestion_Requests_Processed  where usecase_id = '{usecase_parm}') tb1\n",
    "join com_us_alyt_ngebox.METADATA_USECASE tb2 on tb1.usecase_id = tb2.USECASE_ID \n",
    "join com_us_alyt_ngebox.lkp_prod_salesforce  tb3 on tb3.Prod_Nm = tb2.Prod_Nm\n",
    "join com_us_hub.ref_zip_terr tb4 \n",
    "on tb1.hcp_zip_code = tb4.zip_cd and tb3.sf_cd= tb4.sf_cd and tb4.curr_ind = 'Y' and tb4.level = 'Territory' \n",
    "join (select account_vod__c, explode(split(btrim(TERRITORY_VOD__C,';'),';')) as abc from com_us_alyt_omnichannel.ib_ilay_rep_account_territory_loader_v where ISDELETED <> 1) tb5\n",
    "on tb1.account_vod__c = tb5.account_vod__c and tb4.geo_cd = tb5.abc\n",
    "left join com_us_lake.rep_suggestion_vod__c tb6\n",
    "on tb1.SUGGEST_EXTERNAL_ID_VOD__C = tb6.SUGGESTION_EXTERNAL_ID_VOD__C\n",
    "where tb1.usecase_id = '{usecase_parm}' and ((tb6.SUGGESTION_EXTERNAL_ID_VOD__C is NULL) \n",
    "or (tb6.SUGGESTION_EXTERNAL_ID_VOD__C is not null and tb6.DISMISSED_VOD__C = 0))\n",
    "order by tb1.NGEBOX_RECORD_ID,  tb4.geo_cd),\n",
    "\n",
    "p(usecase_id,NG_RECORD_ID,account_vod__c,SUGGEST_EXTERNAL_ID_VOD__C ) AS (select  process_table.usecase_id,process_table.NGEBOX_RECORD_ID, process_table.account_vod__c,process_table.SUGGEST_EXTERNAL_ID_VOD__C from (select * from com_us_alyt_ngebox.NGEBox_Suggestion_Requests_Processed  where usecase_id = '{usecase_parm}') process_table\n",
    "where process_table.usecase_id = '{usecase_parm}'\n",
    "and (case when '{usecase_parm}' IN ('514') then (CAST(process_table.created_date as DATE) = current_date) else CAST(process_table.created_date as DATE) >= date_add(current_date, -(select m.hist_retention from m where m.usecase_id = '{usecase_parm}')) end)\n",
    "and process_table.NGEBox_Record_ID not in (select Record_ID from t where usecase_id = '{usecase_parm}')\n",
    "and process_table.SUGGEST_EXTERNAL_ID_VOD__C in (select SUGGEST_EXTERNAL_ID_VOD__C from s where s.usecase_id ='{usecase_parm}' ))\n",
    "\n",
    "merge into com_us_alyt_ngebox.NGEBox_Suggestion_Requests_Processed process_table using (select distinct usecase_id,NG_RECORD_ID from p where usecase_id = '{usecase_parm}') source_table On (process_table.usecase_id = '{usecase_parm}' and process_table.NGEBOX_RECORD_ID = source_table.NG_RECORD_ID )\n",
    "when matched then update set process_table.Not_Sent_To_Veeva_Reason = (case when ISNULL(process_table.Not_Sent_To_Veeva_Reason)= true then 'Missing ATL in iEngage' else concat(process_table.Not_Sent_To_Veeva_Reason, '|', 'Missing ATL in iEngage' ) end)\"\"\"\n",
    "        self.query = query  \n",
    "\n",
    "  def run_query_and_set_sqldf(self, usecase_id):\n",
    "      self.usecase_id = usecase_id\n",
    "      query_list = self.query.split(\":\")\n",
    "      self.sql_df = [] \n",
    "      for curr_query in query_list:\n",
    "          if curr_query.strip() == \"\":\n",
    "              continue\n",
    "          curr_query_with_param = curr_query.replace(\"Usecase_parm\", usecase_id)\n",
    "          sql_df = sqlContext.sql(curr_query_with_param).collect()\n",
    "          self.sql_df.extend(sql_df)\n",
    "    \n",
    "  def format_sqldf_to_json(self):\n",
    "    sql_output_rowlist = []\n",
    "    for curr_row in self.sql_df: \n",
    "      sql_output_rowlist.append (curr_row.asDict(True))\n",
    "    sql_df_new = pd.DataFrame(sql_output_rowlist)\n",
    "    sql_jsonstr = sql_df_new.to_json(orient=\"records\") # type(result) -> str\n",
    "    sql_jsonparse = json.loads(sql_jsonstr) # type(parsed_json) -> list\n",
    "    nb_json = {\"data\":sql_jsonparse} # type(metadata_json) -> dict\n",
    "    self.nb_json = nb_json\n",
    "    \n",
    "  def construct_microservice_response(self):\n",
    "    resp = {\n",
    "      \"nge_response\": {\n",
    "        \"status\": 200,\n",
    "        \"body\": self.nb_json\n",
    "      }\n",
    "    }\n",
    "    self.response = resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43fec025-64a3-4c06-be3a-2489d2f86d84",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "usecase_id = dbutils.widgets.get(\"usecase_id\")\n",
    "nb_obj = Validate_ATL()\n",
    "nb_obj.set_query_string(usecase_parm=usecase_id)\n",
    "nb_obj.run_query_and_set_sqldf(usecase_id=usecase_id)\n",
    "nb_obj.format_sqldf_to_json()\n",
    "nb_obj.construct_microservice_response()\n",
    "dbutils.notebook.exit(nb_obj.response)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [
    {
     "elements": [],
     "globalVars": {},
     "guid": "",
     "layoutOption": {
      "grid": true,
      "stack": true
     },
     "nuid": "544880d6-2d52-4d1a-8fa6-696857089716",
     "origId": 3683226913856889,
     "title": "Untitled",
     "version": "DashboardViewV1",
     "width": 1024
    }
   ],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "NGE-Box-NB-ATL-Validation-Job",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
